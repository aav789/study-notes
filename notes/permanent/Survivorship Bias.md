---
title: Survivorship Bias
date: 2021-06-01 00:00
tags:
  - Errors of Thinking
cover: /_media/world-war-2-aircraft-survivorship-bias-abraham-wald-17.jpeg
---

Survivorship Bias is a common error of thinking where we arrive at false conclusions by only examining success cases.

For example, on one of my former teams, some of us had been keeping tabs on how well Microservices had worked at NetFlix and we didn't want to miss out. We made a collective decision to start a new project following a strict microservice architecture. 

However, we failed to take into account the countless examples of where they hadn't worked out, discovering for ourselves how much unnecessary complexity they introduce for a small team. This was so common that Thoughtworks named it [Microservice Envy](https://www.thoughtworks.com/radar/techniques/microservice-envy) in their 2015 Radar.

Every page about Survivor Bias has to include the story of Abraham Wald. During WW2, he was instructed to recommend which parts of the planes they should reinforce based on an assessment of their bullet holes. He recommended that they reinforce the parts that took no damage (cover image). The planes that had been hit in other areas presumably didn't make it back. This was at odds with the US military who had recommended targetting the most-hit (the *survivors*).

Another error of thinking like [[Confirmation Bias]].

[@ahrensHowTakeSmart2017] *(pg. 136)*