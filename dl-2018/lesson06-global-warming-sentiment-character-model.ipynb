{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torchtext import data\n",
    "from torch.nn import functional as F\n",
    "from fastai.nlp import LanguageModelData, ConcatTextDatasetFromDataFrames\n",
    "from fastai.lm_rnn import seq2seq_reg\n",
    "from fastai.metrics import accuracy\n",
    "from fastai.core import V\n",
    "from fastai.learner import fit\n",
    "from fastai.column_data import ColumnarModelData\n",
    "from fastai.core import T, VV, to_np\n",
    "from fastai.dataset import get_cv_idxs\n",
    "from fastai.layer_optimizer import set_lrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/raw/global_warming_tweets.csv', encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y      2554\n",
       "NaN    1865\n",
       "N      1053\n",
       "Yes     557\n",
       "No       61\n",
       "Name: existence, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.existence.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>existence</th>\n",
       "      <th>existence.confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global warming report urges governments to act...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fighting poverty and global warming in Africa ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Carbon offsets: How a Vatican forest failed to...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>URUGUAY: Tools Needed for Those Most Vulnerabl...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.8087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet existence  \\\n",
       "0  Global warming report urges governments to act...       Yes   \n",
       "1  Fighting poverty and global warming in Africa ...       Yes   \n",
       "2  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "3  Carbon offsets: How a Vatican forest failed to...       Yes   \n",
       "4  URUGUAY: Tools Needed for Those Most Vulnerabl...       Yes   \n",
       "\n",
       "   existence.confidence  \n",
       "0                1.0000  \n",
       "1                1.0000  \n",
       "2                0.8786  \n",
       "3                1.0000  \n",
       "4                0.8087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.existence = df.existence.replace({'Yes': 'Y', 'No': 'N', pd.np.nan: 'O'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    3111\n",
       "O    1865\n",
       "N    1114\n",
       "Name: existence, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.existence.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1., random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6090"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df.tweet.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_str = ' '.join(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @patrickc: \"The very idea that they care more about safety than we do is as s'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_str[:80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(texts_str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\t', ' ', '!', '\"', '#']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add value for padding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars.insert(0, \"\\0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\t !\"#$%&\\'()*+,-./0123456789:;=?@ABCDEFGHIJKLMNOPQRSTUVWXYZ[\\\\]^_`abcdefghijklmnopqrstuvwxyz{|}~\\x95£´»ÀÁ'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars[1:-6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_to_indices = {}\n",
    "for idx, char in enumerate(chars):\n",
    "    chars_to_indices[char] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_chars = {idx: char  for char, idx in chars_to_indices.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars_to_indices['w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'w'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_chars[87]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = [chars_to_indices[c] for c in texts_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 52, 2, 32, 80, 65, 84, 82, 73, 67]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @patrickc: \"The very idea that they care more about safety than we '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx_to_chars[i] for i in idx[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(chars) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 108\n"
     ]
    }
   ],
   "source": [
    "print(\"total chars:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Character level models can be useful for certain tasks, especially in language translation models: if you find an unknown word, pass to character level models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 3\n",
    "c1_dat = [idx[i] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx) - 1 - cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx) - 1 - cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 32, 84, 67, 28, 52, 2, 82, 73, 65]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c1_dat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R@tc:T riah eceo o fyh     l  olai.-aeEr 9e nsGb rnoumoe.co uo st?BM c'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx_to_chars[i] for i in c1_dat[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tprk hvyd atya rause awdiaslagb rn\" syng( ame)lawmgrnpyn.hsyrwdae:yaJo'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx_to_chars[i] for i in c2_dat[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' aic\"ee etth rmebtattneossiyslawmg Ms ey2ddir olai  elmt.oeo nisr  xab'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx_to_chars[i] for i in c3_dat[:70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tc:T riah eceo o fyh     l  olai.-aeEr 9e nsGb rnoumoe.co uo st?BM cs'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(idx_to_chars[i] for i in c4_dat[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.stack(c1_dat[:-2])\n",
    "x2 = np.stack(c2_dat[:-2])\n",
    "x3 = np.stack(c3_dat[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([50, 32, 84, 67, 28, 52,  2, 82, 73, 65])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and outputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([50, 32, 84, 67]), array([52, 80, 82, 75]), array([ 2, 65, 73, 67]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([32, 84, 67, 28])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((226882,), (226882,))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build char model (non RNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_factors = 42\n",
    "num_hidden_activations = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_width):\n",
    "        super().__init__()\n",
    "        self.emb_layer = nn.Embedding(vocab_size, embedding_width)\n",
    "        \n",
    "        self.input_layer = nn.Linear(embedding_width, num_hidden_activations)\n",
    "        \n",
    "        self.hidden_layer = nn.Linear(num_hidden_activations, num_hidden_activations)\n",
    "        \n",
    "        self.output_layer = nn.Linear(num_hidden_activations, vocab_size)\n",
    "        \n",
    "    def forward(self, char_1, char_2, char_3):\n",
    "        # Get first input activations\n",
    "        input_1 = F.relu(self.input_layer(self.emb_layer(char_1)))\n",
    "        hidden = F.tanh(self.hidden_layer(input_1))\n",
    "        \n",
    "        # Get activations from 2nd layer\n",
    "        input_2 =  F.relu(self.input_layer(self.emb_layer(char_2)))\n",
    "        hidden = F.tanh(self.hidden_layer(hidden + input_2))\n",
    "        \n",
    "        # Now third\n",
    "        input_3 = F.relu(self.input_layer(self.emb_layer(char_3)))\n",
    "        hidden = F.tanh(self.hidden_layer(hidden + input_3))\n",
    "        \n",
    "        return F.log_softmax(self.output_layer(hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226882, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack([x1, x2, x3], axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226882,)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays(\n",
    "    path=Path('.'),\n",
    "    val_idxs=[-1],\n",
    "    xs=np.stack([x1, x2, x3], axis=1),\n",
    "    y=y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Char3Model(vocab_size, num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4261b9ea9884ddd94f7efc290b31106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.771089   0.980628  \n",
      "    1      1.741405   0.739312                              \n",
      "    2      1.715492   0.478331                              \n",
      "    3      1.703063   0.457567                              \n",
      "    4      1.698206   0.342634                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.34263])]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 5, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([chars_to_indices[c] for c in inp]))\n",
    "    probs = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(probs))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('glo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'m'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# war min g\n",
    "get_next('min')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First RNN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Size of the unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = []\n",
    "\n",
    "for i in range(len(idx) - cs):\n",
    "    c = []\n",
    "    \n",
    "    for j in range(cs):\n",
    "        c.append(idx[i + j])\n",
    "        \n",
    "    c_in_dat.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[50, 52, 2, 32, 80, 65, 84, 82],\n",
       " [52, 2, 32, 80, 65, 84, 82, 73],\n",
       " [2, 32, 80, 65, 84, 82, 73, 67],\n",
       " [32, 80, 65, 84, 82, 73, 67, 75],\n",
       " [80, 65, 84, 82, 73, 67, 75, 67],\n",
       " [65, 84, 82, 73, 67, 75, 67, 28],\n",
       " [84, 82, 73, 67, 75, 67, 28, 2],\n",
       " [82, 73, 67, 75, 67, 28, 2, 4],\n",
       " [73, 67, 75, 67, 28, 2, 4, 52],\n",
       " [67, 75, 67, 28, 2, 4, 52, 72]]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in_dat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of the next character in each of these series. This will be the labels for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(c_in_dat, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680646, 8)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(c_out_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50, 52,  2, 32, 80, 65, 84, 82],\n",
       "       [52,  2, 32, 80, 65, 84, 82, 73],\n",
       "       [ 2, 32, 80, 65, 84, 82, 73, 67],\n",
       "       [32, 80, 65, 84, 82, 73, 67, 75],\n",
       "       [80, 65, 84, 82, 73, 67, 75, 67],\n",
       "       [65, 84, 82, 73, 67, 75, 67, 28],\n",
       "       [84, 82, 73, 67, 75, 67, 28,  2],\n",
       "       [82, 73, 67, 75, 67, 28,  2,  4]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs, :cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the next character after each sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73, 67, 75, 67, 28,  2,  4, 52])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', [-1], xs, y, bs=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(model_data.trn_dl))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that without shuffle and without a validation set, the first column matches and column above and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 50\n",
       " 52\n",
       "  2\n",
       " 32\n",
       " 80\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[0][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 52\n",
       "  2\n",
       " 32\n",
       " 80\n",
       " 65\n",
       "[torch.LongTensor of size 5]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[1][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx) - cs - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', [-1], xs, y, bs=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embeddings = nn.Embedding(vocab_size, n_fac)\n",
    "        self.linear_input = nn.Linear(n_fac, num_hidden_activations)\n",
    "        self.linear_hidden = nn.Linear(num_hidden_activations, num_hidden_activations)\n",
    "        self.linear_output = nn.Linear(num_hidden_activations, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        # Get batch size from first column\n",
    "        batch_size = chars[0].size(0)\n",
    "        \n",
    "        # Init hidden state to all 0s\n",
    "        h = V(torch.zeros(batch_size, num_hidden_activations))\n",
    "        \n",
    "        for char in chars:\n",
    "            inp = F.relu(self.linear_input(self.embeddings(char)))\n",
    "            h = F.tanh(self.linear_hidden(h + inp))\n",
    "            \n",
    "        return F.log_softmax(self.linear_output(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57c3f5b87ef45bb8570a81ae27f7d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      2.151497   0.039983  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.03998])]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e523f1a5dbf47dd978033a04403759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.835437   0.0112    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.0112])]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([chars_to_indices[c] for c in inp]))\n",
    "    probs = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(probs))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('global warmin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('climate chan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'x'"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('is a hoa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s'"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('scientific consensu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input state and the hidden state are qualitatively different. Input is the encoding of a character, and h is an encoding of series of characters. So adding them together, we might lose information. Let’s concatenate them instead. Don’t forget to change the input to match the shape (n_fac+n_hidden instead of n_fac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, n_hidden):\n",
    "        super().__init__()\n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.input_layer = nn.Linear(n_hidden + emb_size, n_hidden)\n",
    "        self.hidden_layer = nn.Linear(n_hidden, n_hidden)\n",
    "        self.output_layer = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        batch_size = chars[0].size(0)\n",
    "        hidden = V(torch.zeros(batch_size, self.n_hidden))\n",
    "\n",
    "        for char in chars:\n",
    "            char_emb = self.embedding(char)\n",
    "            \n",
    "            # Concat along columns\n",
    "            inp = torch.cat((hidden, char_emb), 1)\n",
    "            \n",
    "            inp = F.relu(self.input_layer(inp))\n",
    "    \n",
    "            hidden = F.tanh(self.hidden_layer(inp))\n",
    "        \n",
    "        return F.log_softmax(self.output_layer(hidden), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopConcatModel(vocab_size, num_factors, num_hidden_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10607a44015f457da3088dd59e6aa0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.829992   0.017843  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01784])]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5af21fbed654455cb4a330e6f80be3cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.651855   0.008019  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00802])]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26c58e712744d28b5321de4e6a95244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.560111   0.011733  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.01173])]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([chars_to_indices[c] for c in inp]))\n",
    "    probs = model(*VV(idxs))\n",
    "    i = np.argmax(to_np(probs))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'g'"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('global warmin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN with PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = nn.RNN(num_factors, num_hidden_activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden = V(torch.zeros(1, 512, num_hidden_activations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', [-1], xs, y, bs=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "*xs, y = next(iter(model_data.trn_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = nn.Embedding(vocab_size, num_factors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_var = V(torch.stack(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512]),\n",
       " torch.Size([512])]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i.shape for i in inp_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = embedding(inp_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "outp, h = rnn(inp, hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 256])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 256])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 108])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_hidden = n_hidden\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, self.n_hidden)\n",
    "        self.l_out = nn.Linear(self.n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        batch_size = chars[0].size(0)\n",
    "        hidden = V(torch.zeros(1, batch_size, self.n_hidden))\n",
    "        inp = self.embedding(torch.stack(chars))\n",
    "        outp, hidden = self.rnn(inp, hidden)\n",
    "\n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRnn(vocab_size, num_factors, num_hidden_activations)\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 108])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4fe8ecd01c745459351687ab3800d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.856666   0.018851  \n",
      "    1      1.687123   0.006569                                \n",
      "    2      1.597544   0.003674                                \n",
      "    3      1.539042   0.002655                                \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.00265])]"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It'd be ideal if the RNN could store its hidden states in between forward pass, to avoid having to relearn it from scratch each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.lm_rnn import repackage_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, n_hidden, batch_size):\n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_hidden = n_hidden\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(batch_size)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        batch_size = cs[0].size(0)\n",
    "        if self.h.size(1) != batch_size:\n",
    "            self.init_hidden(batch_size)\n",
    "\n",
    "        outp, h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = V(torch.zeros(1, bs, self.n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "bptt = 8\n",
    "n_fac = 42\n",
    "n_hidden = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6090"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df[:5000]\n",
    "val_df = df[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    2541\n",
       "O    1532\n",
       "N     927\n",
       "Name: existence, dtype: int64"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.existence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Y    570\n",
       "O    333\n",
       "N    187\n",
       "Name: existence, dtype: int64"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.existence.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = LanguageModelData.from_dataframes(PATH, TEXT, 'tweet', train_df=train_df, val_df=val_df, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1145"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_data.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl_iter = iter(model_data.trn_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, y = next(trn_dl_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 64])"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs, y = next(trn_dl_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 64])"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence length is different for each mini batch. Makes sense: that part can be anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharSeqStatefulRnn(vocab_size, num_factors, num_hidden_activations, 512)\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23f87cd7a5174a7fa27857ccc328e15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                                \n",
      "    0      1.716935   1.717919  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1.71792])]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = nn.Embedding(vocab_size, embedding_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb_data = embedding_layer(char_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('./data/tmp')\n",
    "PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = LanguageModelData.from_dataframes(PATH, FIELD, 'tweet', train_df, val_df, test_df=test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_data.trn_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Num unique tokens in vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10476"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_data.nt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of sentenecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89166"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_data.trn_ds[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " '<',\n",
       " '>',\n",
       " 'eos',\n",
       " ':',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'global',\n",
       " 'warming']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FIELD.vocab.itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz = 20  # size of each embedding vector\n",
    "nh = 500     # number of hidden activations per layer\n",
    "nl = 3       # number of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = model_data.get_model(\n",
    "    opt_fn, em_sz, nh, nl,\n",
    "    dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)\n",
    "learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learner.clip=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e96da1e17b4e428b910b75e05f4ee4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                            \n",
      "    0      7.490637   6.749711  \n",
      "    1      6.938184   6.199966                            \n",
      "    2      6.503571   6.128257                            \n",
      "    3      6.27187    5.856059                            \n",
      "    4      6.004722   5.699789                            \n",
      "    5      5.777897   5.63743                             \n",
      "    6      5.611077   5.609128                            \n",
      "  0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-357a8890c905>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3e-3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcycle_mult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \"\"\"\n\u001b[0;32m-> 1161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/climate-change-sentiment/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlog_softmax\u001b[0;34m(input, dim, _stacklevel)\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log_softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learner.fit(3e-3, 4, wds=1e-6, cycle_len=1, cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD = data.Field(lower=True, tokenize=\"spacy\")\n",
    "LABEL_FIELD = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import TabularDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.nlp import TextData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, df, text_field, label_field, is_test=False, **kwargs):\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "        examples = []\n",
    "        for i, row in df.iterrows():\n",
    "            label = row.existence\n",
    "            text = row.tweet\n",
    "            examples.append(data.Example.fromlist([text, label], fields))\n",
    "\n",
    "        super().__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    \n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, train_df, val_df=None, test_df=None, **kwargs):\n",
    "        train_data, val_data, test_data = (None, None, None)\n",
    "\n",
    "        if train_df is not None:\n",
    "            train_data = cls(train_df.copy(), text_field, label_field, **kwargs)\n",
    "        if val_df is not None:\n",
    "            val_data = cls(val_df.copy(), text_field, label_field, **kwargs)\n",
    "        if test_df is not None:\n",
    "            test_data = cls(test_df.copy(), text_field, label_field, True, **kwargs)\n",
    "\n",
    "        return tuple(d for d in (train_data, val_data, test_data) if d is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = MyDataset.splits(\n",
    "    text_field=TEXT_FIELD, label_field=LABEL_FIELD, train_df=train_df,\n",
    "    val_df=val_df, test_df=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT_FIELD.build_vocab(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<unk>',\n",
       " '<pad>',\n",
       " ':',\n",
       " 'global',\n",
       " 'climate',\n",
       " 'warming',\n",
       " 'change',\n",
       " 'the',\n",
       " '#',\n",
       " ',',\n",
       " 'to',\n",
       " '.',\n",
       " 'of',\n",
       " '-',\n",
       " '...',\n",
       " 'is',\n",
       " 'in',\n",
       " 'a',\n",
       " 'rt',\n",
       " 'and']"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT_FIELD.vocab.itos[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = TextData.from_splits(PATH, (train_ds, val_ds, test_ds), bs=bs, text_name='text', label_name='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3 = text_data.get_model(opt_fn, 1500, bptt, emb_sz=em_sz, n_hid=nh, n_layers=nl, \n",
    "           dropout=0.1, dropouti=0.65, wdrop=0.5, dropoute=0.1, dropouth=0.3)\n",
    "m3.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "m3.clip=25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4401e5dbbb54a85b1fa097deabcbcb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 47/63 [00:00<00:00, 60.86it/s, loss=0.817]\n",
      "                                                           \r"
     ]
    }
   ],
   "source": [
    "m3.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m3.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "m3.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41401f2f04ca482cb5849d043496324b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.231975   0.629368   0.742811  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.62937]), 0.7428111824938046]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(0.001, 1, metrics=[accuracy], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1176ab53f2540d999f5c3e722f2bda2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=7), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.232341   0.649829   0.738611  \n",
      "    1      0.219688   0.631224   0.74886                   \n",
      "    2      0.216479   0.616329   0.748188                  \n",
      "    3      0.212528   0.587296   0.768201                  \n",
      "    4      0.204572   0.62905    0.742811                  \n",
      "    5      0.194663   0.546126   0.751054                  \n",
      "    6      0.194686   0.555985   0.745499                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.55599]), 0.7454993545368154]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(0.001, 3, metrics=[accuracy], cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eebb57c1f1a41fe84b0603bf1fb2a03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=31), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.18386    0.572231   0.760126  \n",
      "    1      0.180652   0.567026   0.756766                  \n",
      "    2      0.176712   0.577256   0.741299                  \n",
      "    3      0.170845   0.571548   0.760126                  \n",
      "    4      0.176119   0.582053   0.760126                  \n",
      "    5      0.172678   0.585166   0.759454                  \n",
      "    6      0.189165   0.567799   0.759454                  \n",
      "    7      0.183714   0.587814   0.7497                    \n",
      "    8      0.16755    0.572012   0.759454                  \n",
      "    9      0.170211   0.571712   0.759454                  \n",
      "    10     0.170893   0.607364   0.745499                  \n",
      "    11     0.168933   0.590727   0.758614                  \n",
      "    12     0.17155    0.57149    0.759454                  \n",
      "    13     0.17383    0.596397   0.772401                  \n",
      "    14     0.173112   0.591352   0.759454                  \n",
      "    15     0.170239   0.615794   0.769713                  \n",
      "    16     0.16243    0.623734   0.74886                   \n",
      "    17     0.1608     0.600655   0.755926                  \n",
      "    18     0.161367   0.577986   0.762815                  \n",
      "    19     0.169453   0.59273    0.762153                  \n",
      "    20     0.161926   0.594365   0.769041                  \n",
      "    21     0.168601   0.579319   0.755926                  \n",
      "    22     0.1594     0.591576   0.762815                  \n",
      "    23     0.153161   0.579429   0.762815                  \n",
      "    24     0.158072   0.586798   0.762815                  \n",
      "    25     0.158822   0.593257   0.762815                  \n",
      "    26     0.168796   0.596835   0.762815                  \n",
      "    27     0.159346   0.589902   0.758614                  \n",
      "    28     0.156616   0.580322   0.762815                  \n",
      "    29     0.155653   0.587125   0.762815                  \n",
      "    30     0.149502   0.580424   0.756094                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.58042]), 0.7560942044822119]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m3.fit(0.0001, 5, metrics=[accuracy], cycle_mult=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@climate',\n",
       " 'change',\n",
       " 'giant',\n",
       " '#',\n",
       " 'glacier',\n",
       " 'fall',\n",
       " 'in',\n",
       " 'peru',\n",
       " 'causes',\n",
       " 'deadly',\n",
       " 'tsunami',\n",
       " ':',\n",
       " 'http://bit.ly/bvg95c']"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0].examples[10].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
